# Experiment
experiment_name: "qwen-medical-mt"

# Model
base_model: "Qwen/Qwen3-1.7B"
lora:
  r: 16
  alpha: 32
  dropout: 0.0
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"

# Quantization (QLoRA)
quantization:
  load_in_4bit: true
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_use_double_quant: true

# Dataset
dataset:
  hf_repo: "TranDuong/medical-vlsp-2025"
  local_dir: "dataset/medical-vlsp-2025"
  num_parts: 10
  max_train_samples: null  # Full dataset
  max_eval_samples: null   # Full dataset
  max_test_samples: null   # Full dataset

# Training
training:
  num_gpus: 2
  per_device_batch_size: 1
  gradient_accumulation_steps: 1
  num_epochs: 1
  learning_rate: 1.0e-4
  warmup_ratio: 0.0
  max_seq_length: 512
  fp16: true
  gradient_checkpointing: true
  save_steps: 500
  eval_steps: 500
  logging_steps: 10
  save_total_limit: 1

# Evaluation
evaluation:
  max_new_tokens: 128
  generation_batch_size: 8
  comet_model: "Unbabel/wmt22-comet-da"
  comet_batch_size: 8
  log_examples: true
  num_examples_to_log: 100

# Early stopping
early_stopping:
  patience: 2
  min_delta: 0.5
  metric: "bleu"

# W&B
wandb:
  project: "qwen-mt"
  enabled: true

# HuggingFace Hub
huggingface:
  push_best_model: true
  repo_id: "TranDuong/qwen-medical-mt"
  private: true
  push_adapter_only: true

# Output
output_dir: "outputs"
