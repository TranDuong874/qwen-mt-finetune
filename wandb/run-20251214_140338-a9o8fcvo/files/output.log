Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.54s/it]
[34m[1mwandb[0m: [33mWARNING[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.
Creating new LoRA adapter
trainable params: 17,432,576 || all params: 1,738,007,552 || trainable%: 1.0030
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 560.71 examples/s]
  0%|                                                                                                                           | 0/10 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:13<00:00,  1.39s/it]
{'loss': 2.3718, 'grad_norm': 4.909926891326904, 'learning_rate': 0.0001, 'epoch': 0.1}
{'loss': 2.3745, 'grad_norm': 3.292166233062744, 'learning_rate': 9e-05, 'epoch': 0.2}
                                                                                                                                                       
{'eval_loss': 3.275186538696289, 'eval_runtime': 0.4804, 'eval_samples_per_second': 20.818, 'eval_steps_per_second': 4.164, 'epoch': 0.2}
{'loss': 3.0615, 'grad_norm': 5.776799201965332, 'learning_rate': 8e-05, 'epoch': 0.3}
{'loss': 2.879, 'grad_norm': 5.546473026275635, 'learning_rate': 7e-05, 'epoch': 0.4}
{'eval_loss': 3.199831485748291, 'eval_runtime': 0.4576, 'eval_samples_per_second': 21.852, 'eval_steps_per_second': 4.37, 'epoch': 0.4}
{'loss': 2.9242, 'grad_norm': 5.4045233726501465, 'learning_rate': 6e-05, 'epoch': 0.5}
{'loss': 3.9966, 'grad_norm': 8.578989028930664, 'learning_rate': 5e-05, 'epoch': 0.6}
{'eval_loss': 3.141463041305542, 'eval_runtime': 0.4595, 'eval_samples_per_second': 21.762, 'eval_steps_per_second': 4.352, 'epoch': 0.6}
{'loss': 2.8865, 'grad_norm': 4.238473415374756, 'learning_rate': 4e-05, 'epoch': 0.7}
{'loss': 2.1105, 'grad_norm': 2.666637420654297, 'learning_rate': 3e-05, 'epoch': 0.8}
{'eval_loss': 3.1035938262939453, 'eval_runtime': 0.5266, 'eval_samples_per_second': 18.991, 'eval_steps_per_second': 3.798, 'epoch': 0.8}
{'loss': 4.2024, 'grad_norm': 7.760266304016113, 'learning_rate': 2e-05, 'epoch': 0.9}
{'loss': 2.7135, 'grad_norm': 3.9647085666656494, 'learning_rate': 1e-05, 'epoch': 1.0}
{'eval_loss': 3.088122606277466, 'eval_runtime': 0.4684, 'eval_samples_per_second': 21.348, 'eval_steps_per_second': 4.27, 'epoch': 1.0}
{'train_runtime': 13.934, 'train_samples_per_second': 0.718, 'train_steps_per_second': 0.718, 'train_loss': 2.952031636238098, 'epoch': 1.0}
