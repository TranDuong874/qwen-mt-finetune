config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 726/726 [00:00<00:00, 4.39MB/s]
model.safetensors.index.json: 25.6kB [00:00, 54.6MB/s]
model-00002-of-00002.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████| 622M/622M [02:31<00:00, 4.10MB/s]
model-00001-of-00002.safetensors: 100%|███████████████████████████████████████████████████████████████████████████| 3.44G/3.44G [02:46<00:00, 20.7MB/s]
Fetching 2 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [02:48<00:00, 84.39s/it]
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.73s/it]
generation_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 1.07MB/s]
Creating new LoRA adapter
tokenizer_config.json: 9.73kB [00:00, 6.51MB/s]
vocab.json: 2.78MB [00:00, 50.6MB/s]
merges.txt: 1.67MB [00:00, 32.8MB/s]
tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 11.4M/11.4M [00:00<00:00, 12.4MB/s]
trainable params: 17,432,576 || all params: 1,738,007,552 || trainable%: 1.0030
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 210.40 examples/s]
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 1506.85 examples/s]
  0%|                                                                                                                           | 0/10 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.53s/it]
{'loss': 2.3718, 'grad_norm': 4.793544769287109, 'learning_rate': 0.0001, 'epoch': 0.1}
{'loss': 2.3744, 'grad_norm': 3.18056583404541, 'learning_rate': 9e-05, 'epoch': 0.2}
                                                                                                                                                       
{'eval_loss': 3.2772998809814453, 'eval_runtime': 0.5984, 'eval_samples_per_second': 16.711, 'eval_steps_per_second': 3.342, 'epoch': 0.2}
{'loss': 3.0633, 'grad_norm': 5.676181316375732, 'learning_rate': 8e-05, 'epoch': 0.3}
{'loss': 2.8786, 'grad_norm': 5.65026330947876, 'learning_rate': 7e-05, 'epoch': 0.4}
{'eval_loss': 3.205970048904419, 'eval_runtime': 0.4859, 'eval_samples_per_second': 20.581, 'eval_steps_per_second': 4.116, 'epoch': 0.4}
{'loss': 2.9269, 'grad_norm': 5.30772590637207, 'learning_rate': 6e-05, 'epoch': 0.5}
{'loss': 4.0031, 'grad_norm': inf, 'learning_rate': 5e-05, 'epoch': 0.6}
{'eval_loss': 3.1743054389953613, 'eval_runtime': 0.4807, 'eval_samples_per_second': 20.803, 'eval_steps_per_second': 4.161, 'epoch': 0.6}
{'loss': 2.9203, 'grad_norm': 4.408270359039307, 'learning_rate': 4e-05, 'epoch': 0.7}
{'loss': 2.1344, 'grad_norm': 2.762097120285034, 'learning_rate': 3e-05, 'epoch': 0.8}
{'eval_loss': 3.139432430267334, 'eval_runtime': 0.5249, 'eval_samples_per_second': 19.051, 'eval_steps_per_second': 3.81, 'epoch': 0.8}
{'loss': 4.2426, 'grad_norm': 8.003707885742188, 'learning_rate': 2e-05, 'epoch': 0.9}
{'loss': 2.7457, 'grad_norm': 4.033080577850342, 'learning_rate': 1e-05, 'epoch': 1.0}
{'eval_loss': 3.1239352226257324, 'eval_runtime': 0.4676, 'eval_samples_per_second': 21.386, 'eval_steps_per_second': 4.277, 'epoch': 1.0}
{'train_runtime': 15.3648, 'train_samples_per_second': 0.651, 'train_steps_per_second': 0.651, 'train_loss': 2.96610312461853, 'epoch': 1.0}
